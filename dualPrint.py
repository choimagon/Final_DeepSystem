import os
import numpy as np
from PIL import Image
from tqdm import tqdm
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
# import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2

from network.modeling import deeplabv3plus_xception
# from myCl import DualDeepLabV3Plus
# from CBAMDeepLap import DualDeepLabV3Plus
from CBAMDCNV2Deep import DualDeepLabV3Plus
OUTPUT_DIR = 'CBAMSWIN'
os.makedirs(OUTPUT_DIR, exist_ok=True)

output_training_dir = os.path.join(OUTPUT_DIR, 'training_results.png')
output_test_dir = os.path.join(OUTPUT_DIR, 'test_predictions.png')

class FocalTverskyLoss(nn.Module):
    def __init__(self, alpha=0.7, beta=0.3, gamma=1.0, eps=1e-7):
        super(FocalTverskyLoss, self).__init__()
        self.alpha = alpha  # false negative penalty
        self.beta = beta    # false positive penalty
        self.gamma = gamma  # focusing parameter
        self.eps = eps

    def forward(self, inputs, targets):
        # softmax ì ìš©
        inputs = F.softmax(inputs, dim=1)
        
        # ë°°ì¹˜ ì°¨ì› ìœ ì§€í•˜ë©´ì„œ ê³„ì‚°
        batch_size = inputs.size(0)
        total_loss = 0
        
        for b in range(batch_size):
            # í˜„ì¬ ë°°ì¹˜ì˜ ì…ë ¥ê³¼ íƒ€ê²Ÿ
            input_b = inputs[b]  # [C, H, W]
            target_b = targets[b]  # [H, W]
            
            # ê° í´ë˜ìŠ¤ì— ëŒ€í•´ Tversky ì†ì‹¤ ê³„ì‚°
            for c in range(input_b.size(0)):
                # í˜„ì¬ í´ë˜ìŠ¤ì˜ ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿ
                pred_c = input_b[c]  # [H, W]
                target_c = (target_b == c).float()  # [H, W]
                
                # TP, FP, FN ê³„ì‚°
                TP = (pred_c * target_c).sum()
                FP = ((1 - target_c) * pred_c).sum()
                FN = (target_c * (1 - pred_c)).sum()
                
                # Tversky ì†ì‹¤ ê³„ì‚°
                tversky = (TP + self.eps) / (TP + self.alpha * FN + self.beta * FP + self.eps)
                focal_tversky = (1 - tversky) ** self.gamma
                
                total_loss += focal_tversky
        
        return total_loss / batch_size

# ë°ì´í„°ì…‹ ì„¤ì • í•¨ìˆ˜
def setup_dataset_from_aihub(aihub_dir='aihub_dataset', validation_split=0.2):
    print(f"AI Hub ë°ì´í„°ì…‹ í´ë” íƒìƒ‰ ì¤‘: {aihub_dir}")
    
    train_normal_dir = os.path.join(aihub_dir, 'train', 'normal')
    train_masking_dir = os.path.join(aihub_dir, 'train', 'masking')
    val_normal_dir = os.path.join(aihub_dir, 'val', 'normal')
    val_masking_dir = os.path.join(aihub_dir, 'val', 'masking')
    
    if not os.path.exists(train_normal_dir) or not os.path.exists(train_masking_dir):
        print(f"ì˜¤ë¥˜: train í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {train_normal_dir}")
        return None
    if not os.path.exists(val_normal_dir) or not os.path.exists(val_masking_dir):
        print(f"ì˜¤ë¥˜: val í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {val_normal_dir}")
        return None
    
    train_files = sorted([f for f in os.listdir(train_normal_dir) if f.endswith('.jpg') or f.endswith('.png')])
    val_files = sorted([f for f in os.listdir(val_normal_dir) if f.endswith('.jpg') or f.endswith('.png')])
    
    print(f"ë°œê²¬ëœ train ì´ë¯¸ì§€: {len(train_files)}ê°œ")
    print(f"ë°œê²¬ëœ test ì´ë¯¸ì§€: {len(val_files)}ê°œ")
    
    random.shuffle(train_files)
    split_idx = int(len(train_files) * (1 - validation_split))
    train_split_files = train_files[:split_idx]
    val_split_files = train_files[split_idx:]
    
    print(f"í•™ìŠµ ì„¸íŠ¸: {len(train_split_files)}ê°œ")
    print(f"ê²€ì¦ ì„¸íŠ¸: {len(val_split_files)}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(val_files)}ê°œ")
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    def compute_class_weights(files, mask_dir):
        print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
        total_counts = np.zeros(2)  # [ë°°ê²½, ê· ì—´]
        
        for fname in tqdm(files, desc="ë§ˆìŠ¤í¬ ë¶„ì„"):
            path = os.path.join(mask_dir, fname)
            if os.path.exists(path):
                mask_rgb = np.array(Image.open(path).convert("RGB"))
                green_mask = (mask_rgb[:, :, 0] < 50) & (mask_rgb[:, :, 1] > 200) & (mask_rgb[:, :, 2] < 50)
                binary_mask = (green_mask.astype(np.uint8) > 0).astype(np.uint8)
                
                unique, counts = np.unique(binary_mask, return_counts=True)
                for u, c in zip(unique, counts):
                    total_counts[u] += c
        
        total_counts = np.maximum(total_counts, 1)  # 0 ë‚˜ëˆ—ì…ˆ ë°©ì§€
        total = total_counts.sum()
        class_weights = total / (2.0 * total_counts)
        
        print("í´ë˜ìŠ¤ ë¶„í¬:")
        print(f"  - ë°°ê²½: {int(total_counts[0])}í”½ì…€ ({total_counts[0]/total*100:.2f}%)")
        print(f"  - ê· ì—´: {int(total_counts[1])}í”½ì…€ ({total_counts[1]/total*100:.2f}%)")
        print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: [{class_weights[0]:.4f}, {class_weights[1]:.4f}]")
        
        return class_weights
    
    class_weights = compute_class_weights(train_split_files[:min(1000, len(train_split_files))], train_masking_dir)
    
    return {
        'train_files': train_split_files,
        'val_files': val_split_files,
        'test_files': val_files,
        'train_img_dir': train_normal_dir,
        'train_mask_dir': train_masking_dir,
        'val_img_dir': val_normal_dir,
        'val_mask_dir': val_masking_dir,
        'class_weights': class_weights.tolist() if isinstance(class_weights, np.ndarray) else class_weights
    }
# Dataset í´ë˜ìŠ¤
class CrackDataset(Dataset):
    def __init__(self, img_dir, mask_dir, files=None, transform=None):
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.images = files if files is not None else sorted([
            f for f in os.listdir(img_dir) if f.endswith(".jpg") or f.endswith(".png")
        ])
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        img_path = os.path.join(self.img_dir, img_name)
        mask_path = os.path.join(self.mask_dir, img_name)

        image = np.array(Image.open(img_path).convert("RGB"))
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        blur1 = cv2.GaussianBlur(gray, (0, 0), 1.0)
        blur2 = cv2.GaussianBlur(gray, (0, 0), 2.0)
        dog = cv2.subtract(blur1, blur2)
        dog = np.clip(dog, 0, 255).astype(np.uint8)

        # 3ì±„ë„ë¡œ í™•ì¥
        if len(dog.shape) == 2:
            dog = np.stack([dog]*3, axis=2)  # [H, W] â†’ [H, W, 3]

        mask_rgb = np.array(Image.open(mask_path).convert("RGB"))
        green_mask = (mask_rgb[:, :, 0] < 50) & (mask_rgb[:, :, 1] > 200) & (mask_rgb[:, :, 2] < 50)
        binary_mask = (green_mask.astype(np.uint8) > 0).astype(np.uint8)

        if self.transform:
            rgb_trans = self.transform(image=image, mask=binary_mask)
            dog_trans = self.transform(image=dog, mask=binary_mask)
            rgb_tensor = rgb_trans["image"]
            dog_tensor = dog_trans["image"]
            mask_tensor = rgb_trans["mask"].long()
        else:
            rgb_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0
            dog_tensor = torch.from_numpy(dog.transpose(2, 0, 1)).float() / 255.0
            mask_tensor = torch.from_numpy(binary_mask).long()

        return (rgb_tensor, dog_tensor), mask_tensor

# IoU ê³„ì‚° í•¨ìˆ˜
def calculate_iou(pred, target):
    pred = pred.bool()
    target = target.bool()
    intersection = (pred & target).float().sum((1, 2))
    union = (pred | target).float().sum((1, 2))
    iou = (intersection + 1e-6) / (union + 1e-6)
    return iou.mean().item()

# Recall ê³„ì‚° í•¨ìˆ˜
def calculate_recall(pred, target, eps=1e-6):
    pred = pred.bool()
    target = target.bool()
    true_positive = (pred & target).float().sum((1, 2))
    false_negative = (~pred & target).float().sum((1, 2))
    recall = (true_positive + eps) / (true_positive + false_negative + eps)
    return recall.mean().item()

# í•™ìŠµ ì½”ë“œ ìˆ˜ì •
def train_crack_model():
    # ë°ì´í„°ì…‹ ì„¤ì •
    dataset_info = setup_dataset_from_aihub('/home/magon/Downloads/TT/ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ')
    
    if not dataset_info:
        print("ë°ì´í„°ì…‹ ì„¤ì • ì‹¤íŒ¨")
        return
    
    # ì¥ì¹˜ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")
    
    # í•™ìŠµ ë°ì´í„°ë¥¼ ìœ„í•œ augmentationì´ í¬í•¨ëœ transform
    train_transform = A.Compose([
        A.Resize(299,299),
        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
        ToTensorV2()
    ])
    
    # Xception ëª¨ë¸ì„ ìœ„í•œ transforms ì„¤ì •
    test_transform = A.Compose([
        A.Resize(299,299),
        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
        ToTensorV2()
    ])
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = CrackDataset(
        dataset_info['train_img_dir'], 
        dataset_info['train_mask_dir'], 
        files=dataset_info['train_files'],
        transform=train_transform,
    )
    
    val_dataset = CrackDataset(
        dataset_info['train_img_dir'], 
        dataset_info['train_mask_dir'], 
        files=dataset_info['val_files'],
        transform=test_transform,
    )
    
    test_dataset = CrackDataset(
        dataset_info['val_img_dir'], 
        dataset_info['val_mask_dir'], 
        files=dataset_info['test_files'],
        transform=test_transform,
    )
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = DualDeepLabV3Plus(num_classes=2).to(device)
    model = model.to(device)
    
    # ê°€ì¤‘ì¹˜ ì„¤ì •
    if dataset_info['class_weights']:
        class_weights = torch.tensor(dataset_info['class_weights'], dtype=torch.float32)
        print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì‚¬ìš©: {class_weights}")
    else:
        class_weights = None
    
    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
    # criterion = nn.CrossEntropyLoss(weight=class_weights.to(device) if class_weights is not None else None)
    criterion = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=1.0)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    num_epochs = 50
    best_val_loss = float('inf')
    early_stopping_patience = 6
    early_stopping_counter = 0
    
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    history = {
        'train_loss': [],
        'val_loss': [],
        'train_iou': [],
        'val_iou': [],
        'train_dice': [],
        'val_dice': [],
        'train_accuracy': [],
        'val_accuracy': [],
        'train_recall': [],
        'val_recall': []
    }
    
    # í•™ìŠµ ë£¨í”„
    for epoch in range(num_epochs):
        # í•™ìŠµ ëª¨ë“œ
        model.train()
        train_loss = 0
        train_iou = 0
        train_dice = 0
        train_accuracy = 0
        train_recall = 0
        
        for (x_rgb, x_dog), masks in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]'):
            x_rgb, x_dog, masks = x_rgb.to(device), x_dog.to(device), masks.to(device)
            
            # ê·¸ë¼ë””ì–¸íŠ¸ ì´ˆê¸°í™”
            optimizer.zero_grad()
            
            # ìˆœì „íŒŒ
            outputs = model(x_rgb, x_dog)
            loss = criterion(outputs, masks)
            
            # ì—­ì „íŒŒ
            loss.backward()
            optimizer.step()
            
            # ì†ì‹¤ ëˆ„ì 
            train_loss += loss.item()
            
            # IoU ê³„ì‚° (softmax ì ìš© í›„)
            preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)
            iou_val = calculate_iou(preds, masks)
            train_iou += iou_val
            train_dice += (2*iou_val)/(iou_val+1)
            train_accuracy += (preds == masks).float().mean().item()
            train_recall += calculate_recall(preds, masks)
        # ì—í¬í¬ë‹¹ í‰ê·  ì†ì‹¤ ë° IoU
        train_loss /= len(train_loader)
        train_iou /= len(train_loader)
        train_dice /= len(train_loader)
        train_accuracy /= len(train_loader)
        train_recall /= len(train_loader)
        
        # ê²€ì¦ ëª¨ë“œ
        model.eval()
        val_loss = 0
        val_iou = 0
        val_dice = 0
        val_accuracy = 0
        val_recall = 0
        
        with torch.no_grad():
            for (x_rgb, x_dog), masks in tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]'):
                x_rgb, x_dog, masks = x_rgb.to(device), x_dog.to(device), masks.to(device)
                
                # ìˆœì „íŒŒ
                outputs = model(x_rgb, x_dog)
                loss = criterion(outputs, masks)
                
                # ì†ì‹¤ ëˆ„ì 
                val_loss += loss.item()
                
                # IoU ê³„ì‚°
                preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)
                iou_val = calculate_iou(preds, masks)
                val_iou += iou_val
                val_dice += (2*iou_val)/(iou_val+1)
                val_accuracy += (preds == masks).float().mean().item()
                val_recall += calculate_recall(preds, masks)
        
        # ì—í¬í¬ë‹¹ í‰ê·  ê²€ì¦ ì†ì‹¤ ë° IoU
        val_loss /= len(val_loader)
        val_iou /= len(val_loader)
        val_dice /= len(val_loader)
        val_accuracy /= len(val_loader)
        val_recall /= len(val_loader)
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        scheduler.step(val_loss)
        
        # ê²°ê³¼ ì €ì¥
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_iou'].append(train_iou)
        history['val_iou'].append(val_iou)
        history['train_dice'].append(train_dice)
        history['val_dice'].append(val_dice)
        history['train_accuracy'].append(train_accuracy)
        history['val_accuracy'].append(val_accuracy)
        history['train_recall'].append(train_recall)
        history['val_recall'].append(val_recall)
        
        # ì—í¬í¬ ê²°ê³¼ ì¶œë ¥
        print(f'Epoch {epoch+1}/{num_epochs}:')
        print(f'Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Train Dice: {train_dice:.4f}, Train Accuracy: {train_accuracy:.4f}, Train Recall: {train_recall:.4f}')
        print(f'Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}, Val Dice: {val_dice:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Recall: {val_recall:.4f}')
        
        # ìµœì  ëª¨ë¸ ì €ì¥
        if val_loss < best_val_loss:
            early_stopping_counter = 0
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': best_val_loss,
                'iou': val_iou,
                'dice': val_dice,
                'accuracy': val_accuracy,
                'recall': val_recall
            }, os.path.join(OUTPUT_DIR,f'xception_cbam_before_ASPP_{best_val_loss:.4f}_{val_iou:.4f}_{val_dice:.4f}_{val_accuracy:.4f}_{val_recall:.4f}.pth'))
            print(f'ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (Epoch {epoch+1})')
        
        # Early Stopping ì²´í¬
        print(f"val_loss {val_loss} | best_val_loss {best_val_loss}")
        if val_loss > best_val_loss:
            early_stopping_counter += 1
            if early_stopping_counter >= early_stopping_patience:
                print(f"Early Stopping at Epoch {epoch+1}")
                break
    
    # í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
    plot_training_results(history)
    
    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
    print("\ní…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€:")
    test_model(model, test_loader, device, criterion)
    
    return model, history

def plot_training_results(history):
    plt.figure(figsize=(12, 5))
    
    # ì†ì‹¤ ê·¸ë˜í”„
    plt.subplot(1, 3, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Loss per Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    # IoU ê·¸ë˜í”„
    plt.subplot(1, 3, 2)
    plt.plot(history['train_iou'], label='Train IoU')
    plt.plot(history['val_iou'], label='Validation IoU')
    plt.title('IoU per Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('IoU')
    plt.legend()
    
    plt.subplot(1, 3, 3)
    plt.plot(history['train_dice'], label='Train Dice')
    plt.plot(history['val_dice'], label='Validation Dice')
    plt.title('Dice per Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Dice')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(output_training_dir)

def visualize_predictions(model, test_loader, device, num_samples=5):
    model.eval()
    
    # ëœë¤ ë°°ì¹˜ ì„ íƒ
    dataiter = iter(test_loader)
    (x_rgb, x_dog), masks = next(dataiter)
    
    # ìƒ˜í”Œ ìˆ˜ ì œí•œ
    num_samples = min(num_samples, x_rgb.size(0))
    
    x_rgb = x_rgb[:num_samples].to(device)
    x_dog = x_dog[:num_samples].to(device)  # ğŸ”§ ìˆ˜ì •: x_dogë„ deviceë¡œ ë³´ë‚´ê¸°
    masks = masks[:num_samples].to(device)
    
    with torch.no_grad():
        outputs = model(x_rgb, x_dog)
        preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)
    
    fig, axs = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))
    
    for i in range(num_samples):
        # ì›ë³¸ ì´ë¯¸ì§€ - ì •ê·œí™” ë³µì›
        img = x_rgb[i].cpu().permute(1, 2, 0).numpy()
        img = img * 0.5 + 0.5  # [-1,1] -> [0,1]
        
        # ì‹¤ì œ ë§ˆìŠ¤í¬
        mask = masks[i].cpu().numpy()
        
        # ì˜ˆì¸¡ ë§ˆìŠ¤í¬
        pred = preds[i].cpu().numpy()
        
        # ì‹œê°í™”
        axs[i, 0].imshow(img)
        axs[i, 0].set_title('Input image')
        axs[i, 0].axis('off')
        
        axs[i, 1].imshow(mask, cmap='gray')
        axs[i, 1].set_title('True Mask')
        axs[i, 1].axis('off')
        
        axs[i, 2].imshow(pred, cmap='gray')
        axs[i, 2].set_title('Predicted Mask')
        axs[i, 2].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_test_dir)


def test_model(model, test_loader, device, criterion=None):
    model.eval()
    test_iou = 0
    test_loss = 0
    test_dice = 0
    test_accuracy = 0
    test_recall = 0
    
    if not criterion:
        criterion = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=1.0)
    
    def calculate_iou(pred, target):
        pred = pred.bool()
        target = target.bool()
        intersection = (pred & target).float().sum((1, 2))
        union = (pred | target).float().sum((1, 2))
        iou = (intersection + 1e-6) / (union + 1e-6)
        return iou.mean().item()
    
    with torch.no_grad():
        for (x_rgb, x_dog), masks in tqdm(test_loader, desc='í…ŒìŠ¤íŠ¸ ì¤‘'):
            x_rgb, x_dog, masks = x_rgb.to(device), x_dog.to(device), masks.to(device)
            outputs = model(x_rgb, x_dog)
            loss = criterion(outputs, masks)
            test_loss += loss.item()
            
            # Binary segmentationì„ ìœ„í•œ sigmoid ì ìš©
            probs = torch.sigmoid(outputs[:, 1])
            preds = (probs > 0.5).float()
            iou_val = calculate_iou(preds, masks)
            test_iou += iou_val
            test_dice += (2*iou_val)/(iou_val+1)
            test_accuracy += (preds == masks).float().mean().item()
            test_recall += calculate_recall(preds, masks)
            
    test_loss /= len(test_loader)
    test_iou /= len(test_loader)
    test_dice /= len(test_loader)
    test_accuracy /= len(test_loader)
    test_recall /= len(test_loader)
    
    print(f'í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}, í…ŒìŠ¤íŠ¸ IoU: {test_iou:.4f}, í…ŒìŠ¤íŠ¸ Dice: {test_dice:.4f}, í…ŒìŠ¤íŠ¸ Accuracy: {test_accuracy:.4f}, í…ŒìŠ¤íŠ¸ Recall: {test_recall:.4f}')
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™”
    visualize_predictions(model, test_loader, device)
    
    return test_loss, test_iou, test_dice, test_accuracy, test_recall

if __name__ == "__main__":
    train_crack_model()